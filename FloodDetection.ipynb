{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rtRitesh-rgb/colab-push/blob/Flood-Predection-project/FloodDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 756
        },
        "id": "wx6QIlrkf6ls",
        "outputId": "ef1ac0f8-e3ca-479b-a699-c9b6e75b55a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úî All libraries loaded!\n",
            "\n",
            "üì§ Upload training images (optical, SAR, mask TIFFs)\n",
            "Upload format: opticalX.tif, sarX.tif, maskX.tif. Or a single .zip file containing them.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5bba254d-6480-41bc-8494-d5e125efe101\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5bba254d-6480-41bc-8494-d5e125efe101\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving flood_training_sample.zip to flood_training_sample (3).zip\n",
            "Detected zip file: flood_training_sample (3).zip. Extracting...\n",
            "Detected training samples: [('training_data/optical1.tif', 'training_data/sar1.tif', 'training_data/mask1.tif')]\n",
            "\n",
            "üöÄ Training starting...\n",
            "\n",
            "Epoch 1/10 ‚Äî Loss: 0.7524\n",
            "Epoch 2/10 ‚Äî Loss: 0.7488\n",
            "Epoch 3/10 ‚Äî Loss: 0.7452\n",
            "Epoch 4/10 ‚Äî Loss: 0.7415\n",
            "Epoch 5/10 ‚Äî Loss: 0.7378\n",
            "Epoch 6/10 ‚Äî Loss: 0.7335\n",
            "Epoch 7/10 ‚Äî Loss: 0.7313\n",
            "Epoch 8/10 ‚Äî Loss: 0.7290\n",
            "Epoch 9/10 ‚Äî Loss: 0.7263\n",
            "Epoch 10/10 ‚Äî Loss: 0.7231\n",
            "\n",
            "‚úî Model saved as simple_unet.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2ced1385-e2a7-48b0-8aca-17e3c9f1a230\", \"simple_unet.pth\", 108235)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üì§ Upload optical + SAR for prediction\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3466ffce-f1c4-4681-a8ff-88830d0427f6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3466ffce-f1c4-4681-a8ff-88830d0427f6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving optical1.tif to optical1 (1).tif\n",
            "Saving sar1.tif to sar1 (1).tif\n",
            "\n",
            "‚úî Saved flood_mask.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/rasterio/__init__.py:366: NotGeoreferencedWarning: The given matrix is equal to Affine.identity or its flipped counterpart. GDAL may ignore this matrix and save no geotransform without raising an error. This behavior is somewhat driver-specific.\n",
            "  dataset = writer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_85b54722-f4ea-4457-9238-24a3768794bd\", \"flood_mask.tif\", 65826)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîÑ Converting flood mask to polygons...\n",
            "‚úî Saved flood_polygons.geojson\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6f3ae599-a150-4ed7-85ea-412676fb0c07\", \"flood_polygons.geojson\", 197)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üéâ All steps completed! Training ‚Üí Prediction ‚Üí GeoJSON done!\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "#  SIMPLE FLOOD MAPPING (U-NET) - GOOGLE COLAB\n",
        "#  optical + SAR 2-channel input\n",
        "#  Training + Prediction + Polygon Export\n",
        "#  All in one notebook\n",
        "# ============================================\n",
        "\n",
        "!pip install rasterio geopandas shapely opencv-python torch torchvision --quiet\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import rasterio\n",
        "import cv2\n",
        "import json\n",
        "from rasterio.features import shapes\n",
        "from google.colab import files\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "print(\"‚úî All libraries loaded!\")\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# 1. SIMPLE U-NET MODEL\n",
        "# ============================================\n",
        "class SimpleUNet(nn.Module):\n",
        "    def __init__(self, in_ch=2, out_ch=1):\n",
        "        super().__init__()\n",
        "        self.enc1 = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, 16, 3, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(16, 16, 3, padding=1), nn.ReLU()\n",
        "        )\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.enc2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, 3, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, 3, padding=1), nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.up = nn.ConvTranspose2d(32, 16, 2, stride=2)\n",
        "\n",
        "        self.dec1 = nn.Sequential(\n",
        "            nn.Conv2d(32, 16, 3, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(16, 16, 3, padding=1), nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.final = nn.Conv2d(16, out_ch, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        e1 = self.enc1(x)\n",
        "        p = self.pool(e1)\n",
        "        e2 = self.enc2(p)\n",
        "        up = self.up(e2)\n",
        "        if up.shape != e1.shape:\n",
        "            up = F.interpolate(up, size=e1.shape[-2:])\n",
        "        d1 = self.dec1(torch.cat([e1, up], dim=1))\n",
        "        return self.final(d1)\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# 2. SIMPLE TIFF LOADER\n",
        "# ============================================\n",
        "def read_tiff(path):\n",
        "    with rasterio.open(path) as src:\n",
        "        img = src.read(1).astype(\"float32\")\n",
        "        img = (img - img.min()) / (img.max() - img.min() + 1e-6)\n",
        "    return img\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# 3. TRAINING SECTION\n",
        "# ============================================\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class SimpleDataset(Dataset):\n",
        "    def __init__(self, samples):\n",
        "        self.samples = samples\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        o, s, m = self.samples[idx]\n",
        "\n",
        "        opt = read_tiff(o)\n",
        "        sar = read_tiff(s)\n",
        "        mask = read_tiff(m)\n",
        "\n",
        "        H = min(opt.shape[0], sar.shape[0])\n",
        "        W = min(opt.shape[1], sar.shape[1])\n",
        "\n",
        "        opt = cv2.resize(opt, (W, H))\n",
        "        sar = cv2.resize(sar, (W, H))\n",
        "        mask = cv2.resize(mask, (W, H))\n",
        "\n",
        "        img = np.stack([opt, sar], axis=0)\n",
        "        return torch.from_numpy(img).float(), torch.from_numpy(mask).float()\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# UPLOAD TRAINING DATA\n",
        "# ============================================\n",
        "print(\"\\nüì§ Upload training images (optical, SAR, mask TIFFs)\")\n",
        "print(\"Upload format: opticalX.tif, sarX.tif, maskX.tif. Or a single .zip file containing them.\\n\")\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "optical_files = []\n",
        "sar_files = []\n",
        "mask_files = []\n",
        "\n",
        "# Check for a zip file\n",
        "zip_file_name = None\n",
        "for f_name in uploaded.keys():\n",
        "    if f_name.endswith(\".zip\"):\n",
        "        zip_file_name = f_name\n",
        "        break\n",
        "\n",
        "if zip_file_name:\n",
        "    print(f\"Detected zip file: {zip_file_name}. Extracting...\")\n",
        "    # Create a directory to extract files into\n",
        "    extract_dir = \"training_data\"\n",
        "    os.makedirs(extract_dir, exist_ok=True)\n",
        "    with zipfile.ZipFile(zip_file_name, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_dir) # Extract to the new directory\n",
        "\n",
        "    # Now list files from the extracted directory\n",
        "    all_extracted_files = os.listdir(extract_dir)\n",
        "    # Prepend the directory name to the file names\n",
        "    extracted_paths = [os.path.join(extract_dir, f) for f in all_extracted_files]\n",
        "\n",
        "    # Auto-detect files from extracted paths\n",
        "    optical_files = sorted([f for f in extracted_paths if os.path.basename(f).lower().startswith(\"optical\")])\n",
        "    sar_files = sorted([f for f in extracted_paths if os.path.basename(f).lower().startswith(\"sar\")])\n",
        "    mask_files = sorted([f for f in extracted_paths if os.path.basename(f).lower().startswith(\"mask\")])\n",
        "else:\n",
        "    # Original logic for individual file uploads\n",
        "    optical_files = sorted([f for f in uploaded if f.lower().startswith(\"optical\")])\n",
        "    sar_files = sorted([f for f in uploaded if f.lower().startswith(\"sar\")])\n",
        "    mask_files = sorted([f for f in uploaded if f.lower().startswith(\"mask\")])\n",
        "\n",
        "samples = list(zip(optical_files, sar_files, mask_files))\n",
        "print(\"Detected training samples:\", samples)\n",
        "\n",
        "# BUILD DATASET\n",
        "ds = SimpleDataset(samples)\n",
        "dl = DataLoader(ds, batch_size=1, shuffle=True)\n",
        "\n",
        "# TRAIN\n",
        "model = SimpleUNet(2)\n",
        "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "print(\"\\nüöÄ Training starting...\\n\")\n",
        "for epoch in range(10):   # small epochs (Colab friendly)\n",
        "    for img, mask in dl:\n",
        "        logits = model(img)\n",
        "        loss = loss_fn(logits[:, 0], mask)\n",
        "\n",
        "        optim.zero_grad()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/10 ‚Äî Loss: {loss.item():.4f}\")\n",
        "\n",
        "torch.save(model.state_dict(), \"simple_unet.pth\")\n",
        "print(\"\\n‚úî Model saved as simple_unet.pth\")\n",
        "files.download(\"simple_unet.pth\")\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# 4. PREDICTION SECTION\n",
        "# ============================================\n",
        "print(\"\\nüì§ Upload optical + SAR for prediction\")\n",
        "uploaded_pred = files.upload()\n",
        "\n",
        "optical_path = [f for f in uploaded_pred if \"optical\" in f.lower()][0]\n",
        "sar_path     = [f for f in uploaded_pred if \"sar\"     in f.lower()][0]\n",
        "\n",
        "opt = read_tiff(optical_path)\n",
        "sar = read_tiff(sar_path)\n",
        "\n",
        "H = min(opt.shape[0], sar.shape[0])\n",
        "W = min(opt.shape[1], sar.shape[1])\n",
        "\n",
        "opt = cv2.resize(opt, (W, H))\n",
        "sar = cv2.resize(sar, (W, H))\n",
        "\n",
        "img = torch.from_numpy(np.stack([opt, sar], axis=0)).unsqueeze(0)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    mask = torch.sigmoid(model(img))[0, 0].numpy()\n",
        "\n",
        "flood = (mask > 0.5).astype(\"uint8\")\n",
        "\n",
        "# save mask\n",
        "with rasterio.open(optical_path) as src:\n",
        "    meta = src.meta.copy()\n",
        "meta.update({\"count\": 1, \"dtype\": \"uint8\"})\n",
        "\n",
        "with rasterio.open(\"flood_mask.tif\", \"w\", **meta) as dst:\n",
        "    dst.write(flood, 1)\n",
        "\n",
        "print(\"\\n‚úî Saved flood_mask.tif\")\n",
        "files.download(\"flood_mask.tif\")\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# 5. CONVERT MASK TO POLYGONS\n",
        "# ============================================\n",
        "print(\"\\nüîÑ Converting flood mask to polygons...\")\n",
        "\n",
        "def mask_to_geojson(mask_tif, out_geojson):\n",
        "    with rasterio.open(mask_tif) as src:\n",
        "        mask = src.read(1)\n",
        "        transform = src.transform\n",
        "\n",
        "    results = (\n",
        "        {\"geometry\": geom, \"properties\": {\"value\": v}}\n",
        "        for geom, v in shapes(mask.astype(np.int16), mask > 0, transform=transform)\n",
        "        if v == 1\n",
        "    )\n",
        "\n",
        "    fc = {\"type\": \"FeatureCollection\", \"features\": list(results)}\n",
        "\n",
        "    with open(out_geojson, \"w\") as f:\n",
        "        json.dump(fc, f)\n",
        "\n",
        "mask_to_geojson(\"flood_mask.tif\", \"flood_polygons.geojson\")\n",
        "\n",
        "print(\"‚úî Saved flood_polygons.geojson\")\n",
        "files.download(\"flood_polygons.geojson\")\n",
        "\n",
        "print(\"\\nüéâ All steps completed! Training ‚Üí Prediction ‚Üí GeoJSON done!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================================================\n",
        "# SIMPLE IMPACT ASSESSMENT\n",
        "#   - Flood area\n",
        "#   - Buildings affected\n",
        "#   - Population exposed\n",
        "# =======================================================\n",
        "\n",
        "!pip install geopandas rasterstats shapely --quiet\n",
        "\n",
        "import geopandas as gpd\n",
        "import rasterio\n",
        "import numpy as np\n",
        "from rasterstats import zonal_stats\n",
        "import json\n",
        "from rasterio.features import shapes\n",
        "from google.colab import files\n",
        "\n",
        "# Define mask_to_geojson here to make the cell self-contained for polygon generation\n",
        "def mask_to_geojson(mask_tif, out_geojson):\n",
        "    with rasterio.open(mask_tif) as src:\n",
        "        mask = src.read(1)\n",
        "        transform = src.transform\n",
        "\n",
        "    results = (\n",
        "        {\"geometry\": geom, \"properties\": {\"value\": v}}\n",
        "        for geom, v in shapes(mask.astype(np.int16), mask > 0, transform=transform)\n",
        "        if v == 1\n",
        "    )\n",
        "\n",
        "    fc = {\"type\": \"FeatureCollection\", \"features\": list(results)}\n",
        "\n",
        "    with open(out_geojson, \"w\") as f:\n",
        "        json.dump(fc, f)\n",
        "\n",
        "\n",
        "# ------------------------\n",
        "# Ensure flood polygons are up-to-date with flood_mask.tif\n",
        "# ------------------------\n",
        "print(\"\\nüîÑ Regenerating flood polygons from flood_mask.tif...\")\n",
        "mask_to_geojson(\"flood_mask.tif\", \"flood_polygons.geojson\")\n",
        "print(\"‚úî Saved updated flood_polygons.geojson\")\n",
        "\n",
        "# -----------------------\n",
        "# 1. Load flood polygons\n",
        "# -----------------------\n",
        "flood_gdf = gpd.read_file(\"flood_polygons.geojson\")\n",
        "print(\"Loaded polygons:\", len(flood_gdf))\n",
        "\n",
        "# ----------------------------------------------\n",
        "# 2. (OPTIONAL) Upload building footprints layer\n",
        "# ----------------------------------------------\n",
        "\n",
        "print(\"\\nüì§ Upload building footprints (GeoJSON / Shapefile)\")\n",
        "uploaded_bld = files.upload()\n",
        "\n",
        "bld_path = list(uploaded_bld.keys())[0]\n",
        "buildings = gpd.read_file(bld_path)\n",
        "\n",
        "# Reproject to flood CRS\n",
        "if buildings.crs != flood_gdf.crs:\n",
        "    buildings = buildings.to_crs(flood_gdf.crs)\n",
        "\n",
        "# Buildings intersecting flood area\n",
        "buildings_impacted = gpd.overlay(buildings, flood_gdf, how=\"intersection\")\n",
        "\n",
        "# -----------------------------------\n",
        "# Count buildings\n",
        "# -----------------------------------\n",
        "total_buildings_impacted = len(buildings_impacted)\n",
        "print(\"üè¢ Buildings impacted:\", total_buildings_impacted)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 3. (OPTIONAL) Upload population raster for population hit\n",
        "# ---------------------------------------------------------\n",
        "print(\"\\nüì§ Upload population raster (GeoTIFF)\")\n",
        "uploaded_pop = files.upload()\n",
        "\n",
        "pop_path = list(uploaded_pop.keys())[0]\n",
        "\n",
        "# Zonal statistics: sum of population values inside flood area\n",
        "stats = zonal_stats(\n",
        "    flood_gdf,\n",
        "    pop_path,\n",
        "    stats=[\"sum\"],\n",
        "    all_touched=True\n",
        ")\n",
        "\n",
        "total_population = sum(s[\"sum\"] for s in stats if s[\"sum\"] is not None)\n",
        "print(\"üë• Estimated population affected:\", total_population)\n",
        "\n",
        "\n",
        "# --------------------\n",
        "# 4. Flood area\n",
        "# --------------------\n",
        "flood_gdf_area = flood_gdf.to_crs(epsg=3857)\n",
        "area_km2 = flood_gdf_area.geometry.area.sum() / 1_000_000\n",
        "print(\"üåä Flooded area:\", round(area_km2, 3), \"km¬≤\")\n",
        "\n",
        "\n",
        "# --------------------\n",
        "# 5. Save report\n",
        "# --------------------\n",
        "report = {\n",
        "    \"buildings_impacted\": int(total_buildings_impacted),\n",
        "    \"population_affected\": float(total_population),\n",
        "    \"flooded_area_km2\": float(area_km2)\n",
        "}\n",
        "\n",
        "with open(\"impact_report.json\", \"w\") as f:\n",
        "    json.dump(report, f, indent=2)\n",
        "\n",
        "print(\"\\n‚úî Impact report saved as impact_report.json\")\n",
        "\n",
        "files.download(\"impact_report.json\")"
      ],
      "metadata": {
        "id": "pCQuXCsukwk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import rasterio\n",
        "import numpy as np\n",
        "\n",
        "with rasterio.open(\"flood_mask.tif\") as src:\n",
        "    mask = src.read(1)\n",
        "    meta = src.meta\n",
        "\n",
        "mask[50:150, 50:150] = 1  # create artificial flood area\n",
        "\n",
        "with rasterio.open(\"flood_mask.tif\", \"w\", **meta) as dst:\n",
        "    dst.write(mask, 1)\n",
        "\n",
        "print(\"‚úî Added artificial flood to mask\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaiL-_dDpGd9",
        "outputId": "8cf3e41a-532c-412d-a808-594b8206cb03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úî Added artificial flood to mask\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/rasterio/__init__.py:366: NotGeoreferencedWarning: The given matrix is equal to Affine.identity or its flipped counterpart. GDAL may ignore this matrix and save no geotransform without raising an error. This behavior is somewhat driver-specific.\n",
            "  dataset = writer(\n"
          ]
        }
      ]
    }
  ]
}